{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering Assignment**"
      ],
      "metadata": {
        "id": "efwI6PZGCma0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "- In the context of feature engineering, a parameter refers to a value or characteristic that defines or controls some aspect of a transformation, calculation, or model.\n",
        "- It's not a feature itself, but rather something that you set or tune to influence how features are created, modified, or used.\n",
        "\n",
        "- Assigning No.Of Bins to a particular category , Degree of polynomial when dealing with polynomial fatures etc.."
      ],
      "metadata": {
        "id": "KHeiEIdTCylo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is correlation?What does negative correlation mean?\n",
        "- Correlation gives the idea of how well 2 features are related to each other.\n",
        "- Three types of correlation -\n",
        "  - Positive Correlation\n",
        "  - Negative correlation\n",
        "  - Neutral correlation\n",
        "- Negative Correlation between 2 features says that if one feature has an increase the other will have a decrease."
      ],
      "metadata": {
        "id": "5CQeSmJh4GZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "- Machine Learning (ML) is a subfield of Artificial Intelligence (AI) that empowers computer systems to learn from data without being explicitly programmed for every task.\n",
        "- Key Components of ML\n",
        "  - Data\n",
        "  - Features\n",
        "  - Training\n",
        "  - Evaluation\n",
        "  - Fine Tuning\n",
        "  - Prediction"
      ],
      "metadata": {
        "id": "pL-vN5ez4m0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?\n",
        "- The loss values tells how far the model precition is compared to reality.\n",
        "- The more the loss value , the worse the prediction is.\n",
        "- The smaller the loss value is,the better the prection is."
      ],
      "metadata": {
        "id": "oiRD7pUt5vrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are continuous and categorical variables?\n",
        "- Continuos variables are the numerical data features where is not limitation.\n",
        "- Example - Height , Age , Weight etc..\n",
        "- Categorical values are bound to be in a specific range or from a fixed set of values.\n",
        "- Example - Quality Of Product [Good , Bad , Worst]"
      ],
      "metadata": {
        "id": "fHXK_KAU6KoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How do we handle categorical variables in Machine Learning? What are the common t\n",
        "echniques?\n",
        "- We need to handle categorical values as they are mostly in text format and machine learning algorithms cannot handle text.\n",
        "- We use techniques like\n",
        "  - One Hot Encoding\n",
        "  - Label Encoding etc.."
      ],
      "metadata": {
        "id": "dZFCVTSw7F5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What do you mean by training and testing a dataset?\n",
        "- A dataset is divided into 2 parts , one for training and one for testing.\n",
        "- Training dataset is used to teach the ML model how the data is and to learn the underneath patterns.\n",
        "- Testing Dataset is used to evalute how well the model has learned about the patterns in the data."
      ],
      "metadata": {
        "id": "k3xf1die7h4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is sklearn.preprocessing?\n",
        "- sklearn also called as Sci-Kit Learn is a machine learning library solely build to handle most of the tasks in ML domain.\n",
        "- sklearn.preprocessing is modules/part of the scikit learn library that handles data preprocessing like\n",
        "  - Encoding Categorical Data\n",
        "  - Normalizing Data\n",
        "  - Scaling Data etc..."
      ],
      "metadata": {
        "id": "oq1N2kmr8Kal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is a Test set?\n",
        "- A test set in machine learning is a portion of your dataset that you set aside and do not use during the training phase of your model.\n",
        "- Its primary purpose is to evaluate the performance of your trained model on unseen data.\n",
        "- Usually Whole dataset is split in 70:30 or 60:40 ratios for training and testing."
      ],
      "metadata": {
        "id": "-sIOnwIF9Zoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "- We use train_test_split from sklearn.model_selection module to split data into training an testing.\n",
        "- Understand the Problem\n",
        "- Data Collection\n",
        "- Data Preprocessing\n",
        "- Feature Engineering\n",
        "- Model Selection\n",
        "- Training\n",
        "- Evaluation\n",
        "- Hyperparameter Tuning\n",
        "\n"
      ],
      "metadata": {
        "id": "nWvzQY9e92YF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "- EDA : Exploratory Data Analysis\n",
        "- Understand the Data: EDA helps you gain a deep understanding of your dataset, including its structure, variables, and their relationships.\n",
        "- Identify Data Quality Issues: EDA allows you to uncover data quality issues such as missing values, outliers, inconsistencies, and errors."
      ],
      "metadata": {
        "id": "A3vDY7yo-tGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is correlation?\n",
        "- Correlation gives the idea of how well 2 features are related to each other.\n",
        "- Three types of correlation -\n",
        "  - Positive Correlation\n",
        "  - Negative correlation\n",
        "  - Neutral correlation"
      ],
      "metadata": {
        "id": "EqkxgbQx_r80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What does negative correlation mean?\n",
        "- Negative Correlation between 2 features says that if one feature has an increase the other will have a decrease."
      ],
      "metadata": {
        "id": "GD9Q5xDpAra8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can you find correlation between variables in Python?\n",
        "- You can find the correlation between variables in Python using the pandas library, which is widely used for data manipulation and analysis.\n",
        "- correlation_matrix = df.corr()"
      ],
      "metadata": {
        "id": "psZYMdUDBHrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is causation? Explain difference between correlation and causation with an example\n",
        "- Causation means that one event is the direct result of another event. In other words, one variable directly influences or causes a change in another variable.\n",
        "- The key difference between correlation and causation is that correlation does not imply causation.\n",
        "-  Just because two variables are related (correlated) does not mean that one causes the other.\n",
        "-  There might be a third, unobserved variable influencing both, or the relationship could be purely coincidental."
      ],
      "metadata": {
        "id": "6-tTBOr-CBDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "- An Optimizer in machine learning is an algorithm used to adjust the parameters of a model during training to minimize the loss function.\n",
        "- Gradient Descent (and its variants like Stochastic Gradient Descent and Mini-Batch Gradient Descent): These optimizers update parameters in the direction opposite to the gradient of the loss function.\n",
        "- Adam (Adaptive Moment Estimation): Adam is a popular adaptive learning rate optimizer that uses moving averages of past gradients and squared gradients to adjust the learning rate for each parameter.\n",
        "- RMSprop (Root Mean Square Propagation): Similar to Adam, RMSprop uses a moving average of squared gradients to adapt the learning rate, which helps in dealing with vanishing or exploding gradients."
      ],
      "metadata": {
        "id": "Hm9qu1OkDMFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model ?\n",
        "- sklearn.linear_model is a module within the scikit-learn (sklearn) library in Python.\n",
        "- Linear models are a class of models that assume a linear relationship between the input features and the output variable.\n",
        "   - Linear Regression\n",
        "   - Logistic Regression etc..."
      ],
      "metadata": {
        "id": "Q9XthrIcE-Id"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What does model.fit() do? What arguments must be given?\n",
        "- model.fit() method is used to train a machine learning model.\n",
        "- X: This is the training data that contains your features.\n",
        "- y: This is the training data that contains your target variable ."
      ],
      "metadata": {
        "id": "HoEsHszfFw3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What does model.predict() do? What arguments must be given?\n",
        "- model.predict() method is used to make predictions with a trained machine learning model. After you have trained your model using the model.fit() method, you can use predict() to get the model's output for new, unseen data.\n",
        "\n",
        "- The primary argument you must provide to model.predict() is:\n",
        "\n",
        "  - X: This is the data containing the features of the samples for which you want to make predictions."
      ],
      "metadata": {
        "id": "vevvSdVFG256"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What are continuous and categorical variables?\n",
        "- Continuous variables are numerical data features that can take on any value within a given range. There is no limitation on the possible values, and they can be measured on a scale.\n",
        "  - Examples: Height, weight, age, temperature, time, sales revenue.\n",
        "- Categorical variables are features that represent categories or groups. They are bound to be in a specific range or from a fixed set of values. These values are often text-based or can be represented by integers that act as labels.\n",
        "  - Examples:Quality of Product: [Good, Bad, Worst]Color: [Red, Blue, Green]Gender: [Male,Female, Non-binary]\n"
      ],
      "metadata": {
        "id": "z6MYGl7wImRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "- Feature scaling is a data preprocessing technique used to standardize or normalize the range of independent variables (features) in a dataset.\n",
        "  - Standardization (Z-score normalization)\n",
        "  - Normalization (Min-Max scaling)"
      ],
      "metadata": {
        "id": "YptGGStfJoVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. How do we perform scaling in Python?\n",
        "- sklearn.preprocessing module, which provides several scaling methods.\n",
        "- The most common ones are StandardScaler for standardization and MinMaxScaler for normalization."
      ],
      "metadata": {
        "id": "X67oxUooK_kQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is sklearn.preprocessing?\n",
        "- sklearn also called as Sci-Kit Learn is a machine learning library solely build to handle most of the tasks in ML domain.\n",
        "- sklearn.preprocessing is modules/part of the scikit learn library that handles data preprocessing like\n",
        "  - Encoding Categorical Data\n",
        "  - Normalizing Data\n",
        "  - Scaling Data etc..."
      ],
      "metadata": {
        "id": "DhoaHf8-LfZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "- We use train_test_split from sklearn.model_selection module to split data into training an testing."
      ],
      "metadata": {
        "id": "zUAlCauWMF2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Explain data encoding?\n",
        "- Data encoding is a crucial data preprocessing technique used in machine learning to convert categorical variables into a numerical format that machine learning algorithms can understand and process.\n",
        "  - Label Encoding\n",
        "  - One-Hot Encoding etc.."
      ],
      "metadata": {
        "id": "qoeCx4-7MhbE"
      }
    }
  ]
}